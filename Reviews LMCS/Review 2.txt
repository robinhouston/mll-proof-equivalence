The paper is about proof nets for Multiplicative Linear Logic with units (MLL), a notoriously difficult topic. For MLL, indeed, it is generally believed that there cannot be a reasonable notion of proof nets. The problem is that the bottom­rule introduces an untameable form of lack of connectedness.
The mainstream solution is to recover connectedness via the addition of jumps connecting bottom­-links to other links. Such an approach has the drawback of providing a non-­canonical notion of proof net. The paper shows a remarkable and unexpected result: comparing non-­canonical nets is a PSPACE­-complete problem, essentially ruling out any hope of tractable proof nets for MLL.
It is a groundbreaking contribution, and thus I strongly support acceptance.
Beyond the result itself the paper is also relevant because 1) it is the first study about proof nets equivalence (at least that I am aware of) and 2) because of the proof technique, amounting to reduce the reconfiguration problem for nondeterministic constraint logic, known to be PSPACE­-complete, to MLL proof equivalence.
Despite the indisputable relevance of the result, the paper has two drawbacks. First, the context of the paper and the consequences of the result are not properly presented/discussed. Second, while the general proof technique is interesting, the proof itself relies on an encoding that is complex and ad­hoc.

CONTEXT OF THE PAPERI have the impression that the authors do not realize the importance of their own result.From the point of view of the theory of proof nets, the problem concerns how to deal with lack of connectedness. It is formulated in terms of the multiplicative units but this is just for technical convenience. The reason why the problem is relevant is the fact that the bottom unit is a variant of the weakening rule, one of the cornerstones of linear logic. The multiplicative units can indeed be easily encoded by the exponentials (fix a type A and let 1 be encoded as an axiom on A, whose conclusions are connected by a par and then wrapped in a promotion, i.e. !(A^\perp \par A), and let bottom be the weakening on the dual formula). Therefore PSPACE­-completeness of proof equivalence for MLL implies PSPACE­hardness of proof equivalence for MELL. This is the real issue, as the exponentials are the expressive core of linear logic. Essentially, the paper proves that proof nets for MELL are intractable, unless ad-­hoc notions as the mix rules are added, or intractability is encapsulated in the translation from proofs to nets. Such a consequence is not explained in the paper, while there is no doubt that it has to be mentioned as it is the main reason of interest for the result.
Another issue concerns the paragraph of the introduction that mentions the fragments of linear logic for which canonical proof nets are known. I think that the polarized case should be added. Moreover it is said that Intuitionistic MLL with units has a canonical presentation but
no citations are given. Of course, *a citation has to be given*, but that is not the point. Given the results in the paper, Intuitionistic (ME)LL is the only hope for a tractable and expressive theory of proof nets. The intuitionistic case should then be discussed precisely, explaining the differences with the classical case. The canonical presentation of the intuitionistic case that the authors have in mind probably relies on jumps, and thus rewiring and proof equivalence make sense there too. Why is that case tractable? And does tractability rely on the fact that cut­-elimination in the linear case is trivial? Would Intuitionistic MELL be tractable as well?
I also find the third paragraph of page 2 (“Since there can be no canonical representation...”) unsatisfying. It points to alternative ideas in the literature to define the identity of proofs. They have to be discussed, at least briefly. At present the alternative approaches are just cited, without giving any hint of why they would help to treat the units.I am also surprised by the total absence of a discussion of the case of MLL with the MIX rules.A better treatment of the context of the problem cannot be avoided, because it is the reason why the result is interesting. Moreover, it is also the reason that justifies to not take too seriously the many technicalities of the encoding.

THE ENCODINGThe initial idea of the encoding is relatively simple, but along the way a number of adjustments are needed, with the consequence that the reader gets inevitably lost in the details.It is evident that the authors strived to make the paper readable, and some of the pictures are really helpful. In my opinion, however, the technical part of the paper is far from being accessible. Personally, I can locally follow the reasoning, and I have a clue of the global proof, but I would not bet on its correctness.
There are three elements that make the paper hard to grasp:1) Numerical constraints:
in order to guarantee that the rewiring of jumps does not lead out of the set of encodable configurations, the encoding relies on several numerical tricks. Section 3 gives an introduction to the technique by illustrating the encoding of 3-­partition in MLL, already known from the literature. The main result, however, requires more sophisticated tricks. The general idea is clear, but concretely the issue makes the encoding quite unreadable and somewhat hard to trust.2) Parity:​ 
the notion of parity of two proof nets, which is crucial for the proof, is not properly explained. Examples would be very welcome. At some point (def 37) the encoding is adjusted in order to guarantee that two equivalent proof nets have the same parity, but the issue is not explained, letting the reader wonder about the what is going on. Please try to give an example.

3) Soundness/readback:
​soundness of the encoding is proved by means of a retraction of proof nets to configurations, a ‘read­back’, that is treated very quickly at the end of the paper, while it is the crucial point of the proof, and the main reason for the many subtleties of the encoding. The read­back has to be explained properly. In particular many different proof nets may read­back to the same configuration, which is something that has to be stressed and explained slowly and via figures.Related to the above points there are two technical choices that require to be discussed and justified. One is about proof nets and one is about constraint logic.
First, the authors choose to restrict jumps to target 1­formulae and to rewire jumps according to a big­step strategy, building on the work of Hughes. The claimed reason is a simpler procedure for cut­elimination, but configurations are encoded in cut­free nets, so I am not sure that their justification is reasonable. I am not claiming that the choice is not reasonable, simply I would like it to be better motivated. Moreover, there should be a brief explanation of why restricting to have jumps targeting 1­formulae does not affect the complexity of equivalence. I am also not convinced that using a big­step strategy is always preferable. I suspect that small­steps might help for some of the technical details. I want that the authors to motivate their choices and point out where and why it would be inconvenient to use small­step rewiring.
Second, in section 4 it is said that the reconfiguration problem remains PSPACE­complete under a number of restrictions, e.g. fixing constraint at the value 2, but the authors choose the encode the general case, without restrictions. Please explain why. Even the slightest simplification to the encoding would be very welcome, and it seems to me that the restrictions would help a lot in this sense. The only justification I can imagine (for encoding the general case) is that soundness would be harder. But I am not convinced that this is true, and I want the issue to be properly discussed (if the restrictions will not be implemented).

MINOR CORRECTIONS­
 page 4, definition 2: please stress that bottoms can even jump on bottoms.­
 Section 3 (starting at page 8): the purpose and the title of this section are not clear at afirst­­­but even at a second­­­ reading. The aim becomes clear only with the last paragraph (second of page 11), where it is said that the section is meant to illustrate the encoding of numerical constraints. Say it at the beginning of the section, and change the title of the section accordingly.
­ the last paragraph of page 14 is quite obscure, in particular explain “the value m will be unique for each vertex, and used for all constraint elements in the encoding of that vertex”. The following paragraph (on page 15, “To ensure that...”) is also quite obscure, please expand.­
 page 15, paragraph “an edge in a constraint...”: move this paragraph that explains how edges and nodes are meant to be represented before the obscure paragraphs of the previous point.
­
 page 17, figure 13: stress that nets 3,4,5 are all read­back to the same configuration. You should probably recall this figure (and the fact that 3,4,5 read back to the same configuration) later on when discussing soundness of the encoding.­
 page 19, definition 18: the empire is the biggest, not the smallest subnet.­
 page 20, proposition 24: please give a citation for the proof or a sketch of its proof.­
 page 21: please improve the explanation of parity. It is confusing that in the directedtree representation jumps are directed, while the other edges are not. In particular the ending line of the third paragraph is confusing: I guess that f(1) should be associated with j (and not f), and I cannot make sense out of the fact that c(3) is associated to c.­
 page 22-­23: define what a tensor­formula is. Is 1 a tensor formula?­ page 23, lemma 30: I find the proof obscure, please improve the explanation, inparticular of 1) the second inductive case, and 2) why ‘1,1, \bottom \tensor\bottom’ is the base case (related to the previous point). It would also be nice to have a figure giving a concrete example corresponding to figure 15. To understand what was going on I had to draw myself the simplest case, so please help the reader with an additional figure.­ Explain the need of definition 37.